{"ast":null,"code":"import * as faceapi from 'face-api.js';\nconst maxDescriptorDistance = 0.5;\nexport async function loadModels() {\n  const MODEL_URL = process.env.PUBLIC_URL + '/models';\n  await faceapi.loadTinyFaceDetectorModel(MODEL_URL);\n  await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);\n  await faceapi.loadFaceRecognitionModel(MODEL_URL);\n}\nexport async function getFullFaceDescription(blob, inputSize = 512) {\n  // tiny_face_detector options\n  let scoreThreshold = 0.5;\n  const OPTION = new faceapi.TinyFaceDetectorOptions({\n    inputSize,\n    scoreThreshold\n  });\n  const useTinyModel = true; // fetch image to api\n\n  let img = await faceapi.fetchImage(blob); // detect all faces and generate full description from image\n  // including landmark and descriptor of each face\n\n  let fullDesc = await faceapi.detectAllFaces(img, OPTION).withFaceLandmarks(useTinyModel).withFaceDescriptors();\n  return fullDesc;\n}\nexport async function createMatcher(faceProfile) {\n  // Create labeled descriptors of member from profile\n  let members = faceProfile.data;\n  let labeledDescriptors = members.map(member => new faceapi.LabeledFaceDescriptors(faceProfile[member].name, faceProfile[member].descriptors.map(descriptor => new Float32Array(descriptor)))); // Create face matcher (maximum descriptor distance is 0.5)\n\n  let faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, maxDescriptorDistance);\n  return faceMatcher;\n}\nexport function isFaceDetectionModelLoaded() {\n  return !!faceapi.nets.tinyFaceDetector.params;\n}","map":{"version":3,"sources":["C:/Users/shuga/Documents/GitU/IIMAS/iimas_auth_frontend/src/components/api/face.js"],"names":["faceapi","maxDescriptorDistance","loadModels","MODEL_URL","process","env","PUBLIC_URL","loadTinyFaceDetectorModel","loadFaceLandmarkTinyModel","loadFaceRecognitionModel","getFullFaceDescription","blob","inputSize","scoreThreshold","OPTION","TinyFaceDetectorOptions","useTinyModel","img","fetchImage","fullDesc","detectAllFaces","withFaceLandmarks","withFaceDescriptors","createMatcher","faceProfile","members","data","labeledDescriptors","map","member","LabeledFaceDescriptors","name","descriptors","descriptor","Float32Array","faceMatcher","FaceMatcher","isFaceDetectionModelLoaded","nets","tinyFaceDetector","params"],"mappings":"AAAA,OAAO,KAAKA,OAAZ,MAAyB,aAAzB;AAEA,MAAMC,qBAAqB,GAAG,GAA9B;AAEA,OAAO,eAAeC,UAAf,GAA4B;AACjC,QAAMC,SAAS,GAAGC,OAAO,CAACC,GAAR,CAAYC,UAAZ,GAAyB,SAA3C;AACA,QAAMN,OAAO,CAACO,yBAAR,CAAkCJ,SAAlC,CAAN;AACA,QAAMH,OAAO,CAACQ,yBAAR,CAAkCL,SAAlC,CAAN;AACA,QAAMH,OAAO,CAACS,wBAAR,CAAiCN,SAAjC,CAAN;AACD;AAED,OAAO,eAAeO,sBAAf,CAAsCC,IAAtC,EAA4CC,SAAS,GAAG,GAAxD,EAA6D;AAClE;AACA,MAAIC,cAAc,GAAG,GAArB;AACA,QAAMC,MAAM,GAAG,IAAId,OAAO,CAACe,uBAAZ,CAAoC;AACjDH,IAAAA,SADiD;AAEjDC,IAAAA;AAFiD,GAApC,CAAf;AAIA,QAAMG,YAAY,GAAG,IAArB,CAPkE,CASlE;;AACA,MAAIC,GAAG,GAAG,MAAMjB,OAAO,CAACkB,UAAR,CAAmBP,IAAnB,CAAhB,CAVkE,CAYlE;AACA;;AACA,MAAIQ,QAAQ,GAAG,MAAMnB,OAAO,CACzBoB,cADkB,CACHH,GADG,EACEH,MADF,EAElBO,iBAFkB,CAEAL,YAFA,EAGlBM,mBAHkB,EAArB;AAIA,SAAOH,QAAP;AACD;AAED,OAAO,eAAeI,aAAf,CAA6BC,WAA7B,EAA0C;AAC/C;AACA,MAAIC,OAAO,GAAGD,WAAW,CAACE,IAA1B;AAEA,MAAIC,kBAAkB,GAAGF,OAAO,CAACG,GAAR,CACvBC,MAAM,IACJ,IAAI7B,OAAO,CAAC8B,sBAAZ,CACEN,WAAW,CAACK,MAAD,CAAX,CAAoBE,IADtB,EAEEP,WAAW,CAACK,MAAD,CAAX,CAAoBG,WAApB,CAAgCJ,GAAhC,CACEK,UAAU,IAAI,IAAIC,YAAJ,CAAiBD,UAAjB,CADhB,CAFF,CAFqB,CAAzB,CAJ+C,CAc/C;;AACA,MAAIE,WAAW,GAAG,IAAInC,OAAO,CAACoC,WAAZ,CAChBT,kBADgB,EAEhB1B,qBAFgB,CAAlB;AAIA,SAAOkC,WAAP;AACD;AAED,OAAO,SAASE,0BAAT,GAAsC;AAC3C,SAAO,CAAC,CAACrC,OAAO,CAACsC,IAAR,CAAaC,gBAAb,CAA8BC,MAAvC;AACD","sourcesContent":["import * as faceapi from 'face-api.js';\r\n\r\nconst maxDescriptorDistance = 0.5;\r\n\r\nexport async function loadModels() {\r\n  const MODEL_URL = process.env.PUBLIC_URL + '/models';\r\n  await faceapi.loadTinyFaceDetectorModel(MODEL_URL);\r\n  await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);\r\n  await faceapi.loadFaceRecognitionModel(MODEL_URL);\r\n}\r\n\r\nexport async function getFullFaceDescription(blob, inputSize = 512) {\r\n  // tiny_face_detector options\r\n  let scoreThreshold = 0.5;\r\n  const OPTION = new faceapi.TinyFaceDetectorOptions({\r\n    inputSize,\r\n    scoreThreshold\r\n  });\r\n  const useTinyModel = true;\r\n\r\n  // fetch image to api\r\n  let img = await faceapi.fetchImage(blob);\r\n\r\n  // detect all faces and generate full description from image\r\n  // including landmark and descriptor of each face\r\n  let fullDesc = await faceapi\r\n    .detectAllFaces(img, OPTION)\r\n    .withFaceLandmarks(useTinyModel)\r\n    .withFaceDescriptors();\r\n  return fullDesc;\r\n}\r\n\r\nexport async function createMatcher(faceProfile) {\r\n  // Create labeled descriptors of member from profile\r\n  let members = faceProfile.data;\r\n\r\n  let labeledDescriptors = members.map(\r\n    member =>\r\n      new faceapi.LabeledFaceDescriptors(\r\n        faceProfile[member].name,\r\n        faceProfile[member].descriptors.map(\r\n          descriptor => new Float32Array(descriptor)\r\n        )\r\n      )\r\n  );\r\n\r\n  // Create face matcher (maximum descriptor distance is 0.5)\r\n  let faceMatcher = new faceapi.FaceMatcher(\r\n    labeledDescriptors,\r\n    maxDescriptorDistance\r\n  );\r\n  return faceMatcher;\r\n}\r\n\r\nexport function isFaceDetectionModelLoaded() {\r\n  return !!faceapi.nets.tinyFaceDetector.params;\r\n}\r\n"]},"metadata":{},"sourceType":"module"}